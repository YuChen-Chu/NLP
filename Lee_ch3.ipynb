{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'faster', 'harry', 'got', 'to', 'the', 'store', ',', 'the', 'faster', 'harry', ',', 'the', 'faster', ',', 'would', 'get', 'home', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "#從nltk.tokenize套件中輸入TreebankWordTokenizer函式\n",
    "\n",
    "sentence = \"The faster Harry got to the store, the faster Harry, the faster, would get home.\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "token_sequence = tokenizer.tokenize(sentence.lower())\n",
    "print(token_sequence)\n",
    "#將等號右邊的句子指定給 sentence  \n",
    "#將tokenizer指定為TreebankWordTokenizer()\n",
    "#TreebankWordTokenizer()可自動將句子切割成單字，並將標點符號與單字拆開\n",
    "#token_sequence指定為 將句子轉換為小寫後，用tokenizer將句子做切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 4, 'faster': 3, ',': 3, 'harry': 2, 'got': 1, 'to': 1, 'store': 1, 'would': 1, 'get': 1, 'home': 1, '.': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#從collections套件中輸入Counter函式\n",
    "\n",
    "bag_of_words = Counter(token_sequence)\n",
    "print(bag_of_words)\n",
    "#Counter()計算list中每個字出現的次數\n",
    "#print()印出bag_of_words內的字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 4), ('faster', 3), (',', 3), ('harry', 2), ('got', 1), ('to', 1), ('store', 1), ('would', 1), ('get', 1), ('home', 1), ('.', 1)]\n"
     ]
    }
   ],
   "source": [
    "word_list = bag_of_words.most_common()  \n",
    "print(word_list)\n",
    "#most_common() 列出從最頻繁到最少的所有字\n",
    "#print()印出word_lists內的字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "times_harry_appears = bag_of_words['harry']\n",
    "total_words = len(word_list) \n",
    "tf = times_harry_appears/total_words\n",
    "\n",
    "print(tf)\n",
    "#times_harry_appears =  bag_of_words中'harry'出現的次數\n",
    "#word_list 為原始來源中唯一的單字的數量\n",
    "#tf = 'harry'出現的次數/word_list的長度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia article on kites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#從維基百科上摘錄幾段關於風箏的文章，並將文章指定給kite_text\n",
    "kite_text = \"A kite is traditionally a tethered heavier-than-air craft with wing surfaces that react against the air to create lift and drag. A kite consists of wings, tethers, and anchors. Kites often have a bridle to guide the face of the kite at the correct angle so the wind can lift it. A kite's wing also may be so designed so a bridle is not needed; when kiting a sailplane for launch, the tether meets the wing at a single point. A kite may have fixed or moving anchors. Untraditionally in technical kiting, a kite consists of tether-set-coupled wing sets; even in technical kiting, though, a wing in the system is still often called the kite. The lift that sustains the kite in flight is generated when air flows around the kite's surface, producing low pressure above and high pressure below the wings. The interaction with the wind also generates horizontal drag along the direction of the wind. The resultant force vector from the lift and drag force components is opposed by the tension of one or more of the lines or tethers to which the kite is attached. The anchor point of the kite line may be static or moving (e.g., the towing of a kite by a running person, boat, free-falling anchors as in paragliders and fugitive parakites or vehicle). The same principles of fluid flow apply in liquids and kites are also used under water. A hybrid tethered craft comprising both a lighter-than-air balloon as well as a kite lifting surface is called a kytoon. Kites have a long and varied history and many different types are flown individually and at festivals worldwide. Kites may be flown for recreation, art or other practical uses. Sport kites can be flown in aerial ballet, sometimes as part of a competition. Power kites are multi-line steerable kites designed to generate large forces which can be used to power activities such as kite surfing, kite landboarding, kite fishing, kite buggying and a new trend snow kiting. Even Man-lifting kites have been made.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 26, 'a': 20, 'kite': 16, ',': 15, 'and': 10, 'of': 10, 'kites': 8, 'is': 7, 'in': 7, 'or': 6, 'wing': 5, 'to': 5, 'be': 5, 'as': 5, 'lift': 4, 'have': 4, 'may': 4, 'at': 3, 'so': 3, 'can': 3, 'also': 3, 'kiting': 3, 'are': 3, 'flown': 3, 'tethered': 2, 'craft': 2, 'with': 2, 'that': 2, 'air': 2, 'consists': 2, 'tethers': 2, 'anchors.': 2, 'often': 2, 'bridle': 2, 'wind': 2, \"'s\": 2, 'designed': 2, ';': 2, 'when': 2, 'for': 2, 'moving': 2, 'technical': 2, 'even': 2, 'called': 2, 'surface': 2, 'pressure': 2, 'drag': 2, 'force': 2, 'by': 2, 'which': 2, '.': 2, 'used': 2, 'power': 2, 'traditionally': 1, 'heavier-than-air': 1, 'surfaces': 1, 'react': 1, 'against': 1, 'create': 1, 'drag.': 1, 'wings': 1, 'guide': 1, 'face': 1, 'correct': 1, 'angle': 1, 'it.': 1, 'not': 1, 'needed': 1, 'sailplane': 1, 'launch': 1, 'tether': 1, 'meets': 1, 'single': 1, 'point.': 1, 'fixed': 1, 'untraditionally': 1, 'tether-set-coupled': 1, 'sets': 1, 'though': 1, 'system': 1, 'still': 1, 'kite.': 1, 'sustains': 1, 'flight': 1, 'generated': 1, 'flows': 1, 'around': 1, 'producing': 1, 'low': 1, 'above': 1, 'high': 1, 'below': 1, 'wings.': 1, 'interaction': 1, 'generates': 1, 'horizontal': 1, 'along': 1, 'direction': 1, 'wind.': 1, 'resultant': 1, 'vector': 1, 'from': 1, 'components': 1, 'opposed': 1, 'tension': 1, 'one': 1, 'more': 1, 'lines': 1, 'attached.': 1, 'anchor': 1, 'point': 1, 'line': 1, 'static': 1, '(': 1, 'e.g.': 1, 'towing': 1, 'running': 1, 'person': 1, 'boat': 1, 'free-falling': 1, 'anchors': 1, 'paragliders': 1, 'fugitive': 1, 'parakites': 1, 'vehicle': 1, ')': 1, 'same': 1, 'principles': 1, 'fluid': 1, 'flow': 1, 'apply': 1, 'liquids': 1, 'under': 1, 'water.': 1, 'hybrid': 1, 'comprising': 1, 'both': 1, 'lighter-than-air': 1, 'balloon': 1, 'well': 1, 'lifting': 1, 'kytoon.': 1, 'long': 1, 'varied': 1, 'history': 1, 'many': 1, 'different': 1, 'types': 1, 'individually': 1, 'festivals': 1, 'worldwide.': 1, 'recreation': 1, 'art': 1, 'other': 1, 'practical': 1, 'uses.': 1, 'sport': 1, 'aerial': 1, 'ballet': 1, 'sometimes': 1, 'part': 1, 'competition.': 1, 'multi-line': 1, 'steerable': 1, 'generate': 1, 'large': 1, 'forces': 1, 'activities': 1, 'such': 1, 'surfing': 1, 'landboarding': 1, 'fishing': 1, 'buggying': 1, 'new': 1, 'trend': 1, 'snow': 1, 'kiting.': 1, 'man-lifting': 1, 'been': 1, 'made': 1})\n"
     ]
    }
   ],
   "source": [
    "#從collections套件中輸入Counter函式\n",
    "#從nltk.tokenize套件中輸入TreebankWordTokenizer函式\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "tokens = tokenizer.tokenize(kite_text.lower())\n",
    "token_counts = Counter(tokens)\n",
    "print(token_counts)\n",
    "\n",
    "#將tokenizer指定為TreebankWordTokenizer()\n",
    "#tokense指定為 將句子轉換為小寫後，用tokenizer將句子做切割\n",
    "#Counter()計算tokens中每個字出現的次數\n",
    "#印出token_counts的內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'kite': 16, ',': 15, 'kites': 8, 'wing': 5, 'lift': 4, 'may': 4, 'also': 3, 'kiting': 3, 'flown': 3, 'tethered': 2, 'craft': 2, 'air': 2, 'consists': 2, 'tethers': 2, 'anchors.': 2, 'often': 2, 'bridle': 2, 'wind': 2, \"'s\": 2, 'designed': 2, ';': 2, 'moving': 2, 'technical': 2, 'even': 2, 'called': 2, 'surface': 2, 'pressure': 2, 'drag': 2, 'force': 2, '.': 2, 'used': 2, 'power': 2, 'traditionally': 1, 'heavier-than-air': 1, 'surfaces': 1, 'react': 1, 'create': 1, 'drag.': 1, 'wings': 1, 'guide': 1, 'face': 1, 'correct': 1, 'angle': 1, 'it.': 1, 'needed': 1, 'sailplane': 1, 'launch': 1, 'tether': 1, 'meets': 1, 'single': 1, 'point.': 1, 'fixed': 1, 'untraditionally': 1, 'tether-set-coupled': 1, 'sets': 1, 'though': 1, 'system': 1, 'still': 1, 'kite.': 1, 'sustains': 1, 'flight': 1, 'generated': 1, 'flows': 1, 'around': 1, 'producing': 1, 'low': 1, 'high': 1, 'wings.': 1, 'interaction': 1, 'generates': 1, 'horizontal': 1, 'along': 1, 'direction': 1, 'wind.': 1, 'resultant': 1, 'vector': 1, 'components': 1, 'opposed': 1, 'tension': 1, 'one': 1, 'lines': 1, 'attached.': 1, 'anchor': 1, 'point': 1, 'line': 1, 'static': 1, '(': 1, 'e.g.': 1, 'towing': 1, 'running': 1, 'person': 1, 'boat': 1, 'free-falling': 1, 'anchors': 1, 'paragliders': 1, 'fugitive': 1, 'parakites': 1, 'vehicle': 1, ')': 1, 'principles': 1, 'fluid': 1, 'flow': 1, 'apply': 1, 'liquids': 1, 'water.': 1, 'hybrid': 1, 'comprising': 1, 'lighter-than-air': 1, 'balloon': 1, 'well': 1, 'lifting': 1, 'kytoon.': 1, 'long': 1, 'varied': 1, 'history': 1, 'many': 1, 'different': 1, 'types': 1, 'individually': 1, 'festivals': 1, 'worldwide.': 1, 'recreation': 1, 'art': 1, 'practical': 1, 'uses.': 1, 'sport': 1, 'aerial': 1, 'ballet': 1, 'sometimes': 1, 'part': 1, 'competition.': 1, 'multi-line': 1, 'steerable': 1, 'generate': 1, 'large': 1, 'forces': 1, 'activities': 1, 'surfing': 1, 'landboarding': 1, 'fishing': 1, 'buggying': 1, 'new': 1, 'trend': 1, 'snow': 1, 'kiting.': 1, 'man-lifting': 1, 'made': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#輸入nltk套件\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "#從nltk套件中載入名叫stopwords的檔案\n",
    "#使用nltk中的語料庫，引用nltk英文版本的 stopwords\n",
    "\n",
    "tokens = [x for x in tokens if x not in stopwords]  #依序列出所有x，x為在tokens裡的字並且不屬於stopwords\n",
    "kite_count = Counter(tokens) #Counter()計算tokens中每個字出現的次數\n",
    "print(kite_count)  #印出kite_count的內容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07207207207207207\n",
      "0.06756756756756757\n",
      "0.036036036036036036\n",
      "0.02252252252252252\n",
      "0.018018018018018018\n",
      "0.018018018018018018\n",
      "0.013513513513513514\n",
      "0.013513513513513514\n",
      "0.013513513513513514\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.009009009009009009\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n",
      "0.0045045045045045045\n"
     ]
    }
   ],
   "source": [
    "document_vector = []    #建立一個list\n",
    "doc_length = len(tokens)  #doc_length指定為tokens的長度\n",
    "for key, value in kite_count.most_common():     #依序列出kite_count中從最頻繁到最少的所有字與值(key=token,value=出現次數)\n",
    "    document_vector.append(value / doc_length)  #將(每個字出現的次數/tokens的長度)的值加入document_vector\n",
    "\n",
    "for elements in document_vector:\n",
    "    print(elements)   #印出所有在document_vector中的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"The faster Harry got to the store, the faster and faster Harry would get home.\"]   #將docs指定為一個句子\n",
    "docs.append(\"Harry is hairy and faster than Jill.\")    #將'Harry is hairy...'加入docs\n",
    "docs.append(\"Jill is not as hairy as Harry.\")          #將'Jill is not...'加入docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The faster Harry got to the store, the faster Harry, the faster, would get home.',\n",
       " 'Harry is hairy and faster than Jill.',\n",
       " 'Jill is not as hairy as Harry.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs  #印出docs的內容(總共有3個句子)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tokens = []    #建立一個list\n",
    "for doc in docs:   #依序列出docs的句子\n",
    "    doc_tokens = doc_tokens + [sorted(tokenizer.tokenize(doc.lower()))] \n",
    "    #先將句子轉換為小寫後，用tokenizer將句子切割成單字\n",
    "    #將切割後的單字重新排列順序(數字在前，英文在後，大寫優於小寫)，並加入doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(tokenizer.tokenize(docs[0].lower())))\n",
    "#將docs裡的第0列句子轉換為小寫後，用tokenizer將句子切割成單字，並重新排列順序後印出長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_tokens[0])\n",
    "#docs裡的第0列句子的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc_tokens = sum(doc_tokens, [])   #將doc_tokens每一列的字加總\n",
    "len(all_doc_tokens)  #印出ll_doc_tokens的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = sorted(set(all_doc_tokens)) #用set()創建一個不重複的元素集，並重新排序\n",
    "len(lexicon) #印出lexicon的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'and',\n",
       " 'as',\n",
       " 'faster',\n",
       " 'get',\n",
       " 'got',\n",
       " 'hairy',\n",
       " 'harry',\n",
       " 'home',\n",
       " 'is',\n",
       " 'jill',\n",
       " 'not',\n",
       " 'store',\n",
       " 'than',\n",
       " 'the',\n",
       " 'to',\n",
       " 'would']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon #lexicon為all_doc_tokens的不重複的元素集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(',', 0), ('.', 0), ('and', 0), ('as', 0), ('faster', 0), ('get', 0), ('got', 0), ('hairy', 0), ('harry', 0), ('home', 0), ('is', 0), ('jill', 0), ('not', 0), ('store', 0), ('than', 0), ('the', 0), ('to', 0), ('would', 0)])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "#從collections套件中輸入OrderedDict函式\n",
    "# OrderedDict()為一個有順序性的字典\n",
    "\n",
    "zero_vector = OrderedDict((token, 0) for token in lexicon) #將lexicon裡的字設成字典，並將索引設成0\n",
    "print(zero_vector) #印出zero_vector的內容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy #輸入copy套件\n",
    "\n",
    "doc_vectors = [] #建立一個list\n",
    "for doc in docs:\n",
    "\n",
    "    vec = copy.copy(zero_vector)              #創建一個獨立的副本，而不是重用對原始對象的內存位置的引用，以免覆蓋原始檔案。\n",
    "    tokens = tokenizer.tokenize(doc.lower())  #將doc句子轉換為小寫後，用tokenizer將句子切割成單字\n",
    "    token_counts = Counter(tokens)            #Counter()計算tokens中每個字出現的次數\n",
    "\n",
    "    for key, value in token_counts.items():\n",
    "        vec[key] = value / len(lexicon)   \n",
    "    doc_vectors.append(vec)\n",
    "    # 將 tokens中每個字出現的次數 /lexicon的長度並將對應的值加入doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math #輸入math套件\n",
    "\n",
    "#def為自訂函式\n",
    "def cosine_sim(vec1, vec2):\n",
    "\n",
    "    vec1 = [val for val in vec1.values()] #列出vec1中的值\n",
    "    vec2 = [val for val in vec2.values()] #列出vec2中的值\n",
    "    \n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]   #dot_prod為將vec1中的值與對應vec2相同位置的值做相乘\n",
    "        \n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))  #將vec1中的值平方後相加在開根號\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))  #將vec2中的值平方後相加在開根號\n",
    "    \n",
    "    return dot_prod / (mag_1 * mag_2)\n",
    "#只要叫出cosine_sim函式，並給定vec1、vec2，將會回傳(dot_prod / (mag_1 * mag_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\harry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161192\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "print(len(brown.words()))     \n",
    "#從nltk中下載brown檔案\n",
    "#從nltk.corpus套件中輸入brown\n",
    "#印出brown的字的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'Grand',\n",
       " 'Jury',\n",
       " 'said',\n",
       " 'Friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words()[:10] #列出前10個字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_words()[:5]  #brown.tagged_words()整理出brown語料庫中指定類別的單詞並附上詞性標籤做成特徵集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 69971), ('of', 36412), ('and', 28853), ('to', 26158), ('a', 23195), ('in', 21337), ('that', 10594), ('is', 10109), ('was', 9815), ('he', 9548), ('for', 9489), ('it', 8760), ('with', 7289), ('as', 7253), ('his', 6996), ('on', 6741), ('be', 6377), ('at', 5372), ('by', 5306), ('i', 5164)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#從collections套件中輸入Counter函式\n",
    "\n",
    "puncs = [',', '.', '--', '-', '!', '?', ':', ';', '``', \"''\", '(', ')', '[', ']']\n",
    "word_list = [x.lower() for x in brown.words() if x not in puncs]  #列出brown.words中的字但不屬於puncs中的標點符號，並且將字轉為小寫\n",
    "token_counts = Counter(word_list)    #Counter()計算word_list中每個字出現的次數\n",
    "print(token_counts.most_common(20))  #most_common(20) 列出從最頻繁到最少的前20個字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_text = 'Kites were invented in China, where materials ideal for kite building were readily available: silk fabric for sail material; fine, high-tensile-strength silk for flying line; and resilient bamboo for a strong, lightweight framework. The kite has been claimed as the invention of the 5th-century BC Chinese philosophers Mozi (also Mo Di) and Lu Ban (also Gongshu Ban). By 549 AD paper kites were certainly being flown, as it was recorded that in that year a paper kite was used as a message for a rescue mission. Ancient and medieval Chinese sources describe kites being used for measuring distances, testing the wind, lifting men, signaling, and communication for military operations. The earliest known Chinese kites were flat (not bowed) and often rectangular. Later, tailless kites incorporated a stabilizing bowline. Kites were decorated with mythological motifs and legendary figures; some were fitted with strings and whistles to make musical sounds while flying. From China, kites were introduced to Cambodia, Thailand, India, Japan, Korea and the western world. After its introduction into India, the kite further evolved into the fighter kite, known as the patang in India, where thousands are flown every year on festivals such as Makar Sankranti. Kites were known throughout Polynesia, as far as New Zealand, with the assumption being that the knowledge diffused from China along with the people. Anthropomorphic kites made from cloth and wood were used in religious ceremonies to send prayers to the gods. Polynesian kite traditions are used by anthropologists get an idea of early \"primitive\" Asian traditions that are believed to have at one time existed in Asia.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_text = kite_text.lower()   #將kite_text中的字皆轉為小寫\n",
    "intro_tokens = tokenizer.tokenize(intro_text) #用tokenizer將句子切割成單字\n",
    " \n",
    "history_text = history_text.lower()   #將history_text中的字皆轉為小寫\n",
    "history_tokens = tokenizer.tokenize(history_text)   #用tokenizer將句子切割成單字\n",
    "intro_total = len(intro_tokens)     #intro_total指定為intro_tokens的長度\n",
    "history_total = len(history_tokens) #history_total指定為history_tokens的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_total  #為intro_tokens的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_total  #為history_tokens的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency of \"kite\" in intro is: 0.0440771349862259\n",
      "Term Frequency of \"kite\" in history is: 0.020202020202020204\n"
     ]
    }
   ],
   "source": [
    "intro_tf = {}           #建立一個字典\n",
    "history_tf = {}         #建立一個字典\n",
    "intro_counts = Counter(intro_tokens)  #Counter()計算intro_tokens中每個字出現的次數\n",
    "intro_tf['kite'] = intro_counts['kite'] / intro_total  #在intro_tf字典中建立kite，值=('kite'出現的次數/intro_total)\n",
    "history_counts = Counter(history_tokens)  #Counter()計算history_tokens中每個字出現的次數\n",
    "history_tf['kite'] = history_counts['kite'] / history_total  #在history_tf字典中建立kite，值=('kite'出現的次數/history_total)\n",
    "print('Term Frequency of \"kite\" in intro is: {}'.format(intro_tf['kite'])) \n",
    "print('Term Frequency of \"kite\" in history is: {}'.format(history_tf['kite']))\n",
    "#.format()為格式指定器，將{}內的值指定為()內的值\n",
    "#印出字串'Term Frequency of \"kite\" in history is: (intro_tf['kite'])的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency of \"and\" in intro is: 0.027548209366391185\n",
      "Term Frequency of \"and\" in history is: 0.030303030303030304\n"
     ]
    }
   ],
   "source": [
    "intro_tf['and'] = intro_counts['and'] / intro_total    #在intro_tf字典中建立and，值=('and出現的次數/intro_total)\n",
    "history_tf['and'] = history_counts['and'] / history_total   #在history_tf字典中建立and，值=('and'出現的次數/history_total)\n",
    "print('Term Frequency of \"and\" in intro is: {}'.format(intro_tf['and']))\n",
    "print('Term Frequency of \"and\" in history is: {}'.format(history_tf['and']))\n",
    "#.format()為格式指定器，將{}內的值指定為()內的值\n",
    "#印出字串'Term Frequency of \"and\" in history is: (intro_tf['and'])的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_containing_and = 0\n",
    "for doc in [intro_tokens, history_tokens]:  \n",
    "    if 'and' in doc:      \n",
    "        num_docs_containing_and += 1\n",
    "#依序列出在intro_tokens、history_tokens的字，如果and有出現在文檔中，就將num_docs_containing_and+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_containing_kite = 0\n",
    "for doc in [intro_tokens, history_tokens]:\n",
    "    if 'kite' in doc:\n",
    "        num_docs_containing_kite += 1\n",
    "#依序列出在intro_tokens、history_tokens的字，如果kite有出現在文檔中，就將num_docs_containing_kite+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_containing_china = 0\n",
    "for doc in [intro_tokens, history_tokens]:\n",
    "    if 'china' in doc:\n",
    "        num_docs_containing_china += 1\n",
    "#依序列出在intro_tokens、history_tokens的字，如果china有出現在兩個文檔中，就將num_docs_containing_china+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf['china'] = intro_counts['china'] / intro_total       #在intro_tf字典中建立china，值=('china出現的次數/intro_total)\n",
    "history_tf['china'] = history_counts['china'] / history_total #在history_tf字典中建立china，值=('china'出現的次數/history_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 2                #將文檔數量指定為2\n",
    "intro_idf = {}              #建立一個字典\n",
    "history_idf = {}            #建立一個字典\n",
    "intro_idf['and'] = num_docs / num_docs_containing_and        #文檔總數/出現and的文檔總數\n",
    "history_idf['and'] = num_docs / num_docs_containing_and      #文檔總數/出現and的文檔總數\n",
    "intro_idf['kite'] = num_docs / num_docs_containing_kite      #文檔總數/出現kite的文檔總數\n",
    "history_idf['kite'] = num_docs / num_docs_containing_kite    #文檔總數/出現kite的文檔總數\n",
    "intro_idf['china'] = num_docs / num_docs_containing_china    #文檔總數/出現china的文檔總數\n",
    "history_idf['china'] = num_docs / num_docs_containing_china  #文檔總數/出現china的文檔總數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tfidf = {}       #建立一個字典\n",
    "\n",
    "intro_tfidf['and'] = intro_tf['and'] * intro_idf['and']       #intro_tfidf['and']為(and在intro文檔中出現的頻率)*(文檔總數/出現and的文檔總數)\n",
    "intro_tfidf['kite'] = intro_tf['kite'] * intro_idf['kite']    #intro_tfidf['kite']為(kite在intro文檔中出現的頻率)*(文檔總數/出現kite的文檔總數)\n",
    "intro_tfidf['china'] = intro_tf['china'] * intro_idf['china'] #intro_tfidf['china']為(china在intro文檔中出現的頻率)*(文檔總數/出現china的文檔總數)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tfidf_vectors = []  #建立一個list\n",
    "documents = docs             \n",
    "for doc in documents:\n",
    "\n",
    "    vec = copy.copy(zero_vector)              #創建一個獨立的副本，而不是重用對原始對象的內存位置的引用，以免覆蓋原始檔案。\n",
    "\n",
    "    tokens = tokenizer.tokenize(doc.lower())  #將doc句子轉換為小寫後，用tokenizer將句子切割成單字\n",
    "    token_counts = Counter(tokens)            #Counter()計算tokens中每個字出現的次數\n",
    "\n",
    "    for key, value in token_counts.items():\n",
    "        docs_containing_key = 0\n",
    "        for _doc in documents:\n",
    "            if key in _doc:\n",
    "                docs_containing_key += 1\n",
    "        tf = value / len(lexicon)\n",
    "        if docs_containing_key:\n",
    "            idf = len(documents) / docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf * idf \n",
    "    document_tfidf_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5235048549676834\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "query = \"How long does it take to get to the store?\"\n",
    "\n",
    "query_vec = copy.copy(zero_vector)           #創建一個獨立的副本，而不是重用對原始對象的內存位置的引用，以免覆蓋原始檔案。\n",
    "\n",
    "tokens = tokenizer.tokenize(query.lower())  #將doc句子轉換為小寫後，用tokenizer將句子切割成單字\n",
    "token_counts = Counter(tokens)              #Counter()計算tokens中每個字出現的次數\n",
    "\n",
    "for key, value in token_counts.items():\n",
    "    docs_containing_key = 0\n",
    "    for _doc in documents:\n",
    "        if key in _doc.lower():\n",
    "            docs_containing_key += 1\n",
    "    if docs_containing_key == 0: \n",
    "        continue\n",
    "    tf = value / len(tokens)\n",
    "    idf = len(documents) / docs_containing_key \n",
    "    query_vec[key] = tf * idf \n",
    "\n",
    "print(cosine_sim(query_vec, document_tfidf_vectors[0]))\n",
    "print(cosine_sim(query_vec, document_tfidf_vectors[1]))\n",
    "print(cosine_sim(query_vec, document_tfidf_vectors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1614879  0.         0.48446369 0.21233718 0.21233718 0.\n",
      "  0.25081952 0.21233718 0.         0.         0.         0.21233718\n",
      "  0.         0.63701154 0.21233718 0.21233718]\n",
      " [0.36930805 0.         0.36930805 0.         0.         0.36930805\n",
      "  0.28680065 0.         0.36930805 0.36930805 0.         0.\n",
      "  0.48559571 0.         0.         0.        ]\n",
      " [0.         0.75143242 0.         0.         0.         0.28574186\n",
      "  0.22190405 0.         0.28574186 0.28574186 0.37571621 0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = docs\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1)     #如果某個詞的document frequence小於min_df，則這個詞不會被當作關鍵詞\n",
    "model = vectorizer.fit_transform(corpus)   #學習詞彙和IDF，返回術語文檔矩陣\n",
    "\n",
    "\n",
    "\n",
    "print(model.todense()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
